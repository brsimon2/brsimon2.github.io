---
title: The Future of Apache Spark
author: Bradley Simon
date: '2020-03-07'
slug: the-future-of-apache-spark
categories:
  - blog
tags: []
---
Apache Spark is an open-source, distributed, large-scale data processing engine. It is an improvement to the MapReduce framework in that it uses in-memory processing to increase speeds by around 100 times. It can also stream data real-time, and it supports many programming languages such as Scala, Java, Python, SQL, and R. All of these features make Apache Spark, complemented with the Spark MLlib (machine learning library) package, very useful in deep learning. What is the difference between machine learning and deep learning? Machine learning uses algorithms that can modify themselves through the input of structured data. However, deep learning is the future as it uses "artificial nueral networks," or layers of algorithms to interpret both unstrucuted and structured data. Deep learning algorithms require much larger amounts of data, and Apache Spark has both the scalability and the speed to process these massive amounts of structured and unstructured data. Yahoo is one company that is currently using Apache Spark and TensorFlow to achieve deep learning, and I believe that many more major companies will continue to follow this trend.